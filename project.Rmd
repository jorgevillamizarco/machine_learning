---
title: "Machine Learning Project"
author: "Jorgevillamizarco"
date: "Thursday, September 20, 2014"
output: html_document
---

##Executive summary

The purpose of the present document is to analyze data captured by Groupware for HAR (Human Activity Recognition) experiments and propose a machine learning algorithm for “classe” variable prediction. Prediction model will be tested with 20 scenarios.

##Getting and Cleaning Data

First we need to download all necessary data and load it removing all missing values using the following code lines:

```{r}
traindata <- read.table("./pml-training.csv", sep=",", na.strings = c("", "NA", "#DIV/0!"), header=TRUE)
testdata <- read.table("./pml-testing.csv", sep=",", na.strings = c("", "NA", "#DIV/0!"), header=TRUE)
```

traingdata dataset will be used for model creation, training, error calculation and model validation, while testdata dataset will be used for prediction.
With a first look over traindata we can see that there’s a lot of variables with missing values, so in order to get a simpler dataset it’s necessary to remove those variables, first calculating the number of NA’s for each column and then removing all columns with 90% or more of NA’s:


```{r}
nas <- apply(traindata, 2, function(x) sum(is.na(x)))
nas < 0.9*nrow(traindata)
traindata <- traindata[,(nas < 0.9*nrow(traindata))]
```


First 8 columns are removed too because they have information not necessaire for model creation and finally “classe” variable is converted to factor:

```{r}
traindata <- traindata[, 8:dim(traindata)[2]]
traindata$classe <- as.factor(traindata$classe)
```

For testdata dataset it’s necessary to remove all variables that were removed from traindata dataset because for next steps we’ll need those two dataset with equal lengths:

```{r}
defcols <- names(traindata)
testdata <- testdata[, (colnames(testdata) %in% defcols)]
```

##Model Creation

In this step, we are going to create, train, test and calculate errors, so first we need to subset traindata into training (train variable) and testing (test variable) sets for posterior cross-validation:

```{r}
library(caret)
library(randomForest)
trainingIndex  <- createDataPartition(traindata$classe, p=.60, list=FALSE)
train <- traindata[ trainingIndex,]
test  <- traindata[-trainingIndex,]
```

Prediction model will be created using random forest methodology, the reason for this is that this methodology offers a better accuracy by de-correlating individual random trees and it gives the variable importance which is very useful to detect the most influential variables in model in order to simplify it. Seed is set to a given value for results reproduction, randomForest function is used with “train” subset previously obtained, “classe” as the outcome, “ntree” for setting the number of trees to create, “nodes” to specify the minimum number of variables per each node of the tree and “importance” set in True for variable importance calculation:

```{r}
set.seed(10)
model <- randomForest(train[,-53], train$classe, ntree=100, nodesize=10, importance=T)
```

Predict and confusionMatrix functions are used to test model and obtain cross-validation results. Prediction result is assigned to “pred” variable, then this one is used in confusionMatrix function to obtain the sample error:

```{r}
pred <- predict(model, test)
confusionMatrix(pred,test$classe)
```

As we can see, the accuracy of the model is more than 99%, and Kappa for statistical relation between model and test subset is 0.98, so, as we expected we have a pretty accurate and low error model.
Using “importance” function we can see which the most influential variables in the model are, the using “varImpPlot” we can see it graphically:

```{r}
sort(importance(model)[,1], decreasing=T)
varImpPlot(model, type=1)
```

This is very helpful because we can simplify our model to a newer one in where we just use the most influential variables in order to have smaller and faster decision trees.

##Prediction

Prediction will be performed using the “predict” function with model and testdata (20 cases to be predicted) as inputs:

```{r}
result <- predict(model, newdata=testdata)
result
```

In order to submit result as text files to prediction assignment it’s necessary to use the next function and call:

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(result)
```

Results uploading give a 20/20 score, confirming the accuracy and quality of the model.